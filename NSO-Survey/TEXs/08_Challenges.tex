\section{Challenges and research opportunities}
\label{sec:challenge}

\gls{nso} promises to improve efficiency when instantiating (day~1) and operating (day~2) network services, but the path ahead is not without  challenges. 
This section provides a discussion on the main challenges and research opportunities for \gls{nso}, including scalability, security, resource modeling, performance, and interoperability.

\subsection{Interoperability}

Typically, operators infrastructures are organized in several domains that differ in geographical locations, management (e.g., legacy or \gls{sdn}), administrative boundaries, and technologies. One of the challenges for service providers is to create and to manage services across unique and proprietary interfaces, making integration and startup difficult tasks to be achieved, as well as increasing the operational costs.  

In this scenario, interoperability is essential to enable the deployment of end-to-end network services. Few end-to-end services will be confined within the boundaries of a single domain. They normally encompass a multi-domain orchestration environment composed of providers and vendors with different incentives and business models~\cite{Katsalis2016Multi-DomainDirections}. There is no consensus about how would be the exchanging process between the multiple actors in deployment end-to-end network services. In fact, \gls{etsi} \gls{mano} architecture does not bring any provisioning for this kind of exchange~\cite{ETSIIndustrySpecificationGroupISGNFV2014NetworkNFV}. 

A number of orchestration solutions based on the ETSI MANO architecture have emerged with the objective of proposing a complete orchestration framework. Table~\ref{tab:NSOsolutions} shows notable solutions. Although the progress made by ETSI in defining architecture and interfaces, each solution uses a particular implementation and data model, which makes interoperability difficult to achieve (cf.~\cite{NOn}). As a result, chaining network functions leveraging different solutions for a single network service deployment and operation is currently a very costly proposition regarding development efforts and time-to-market.   

Standardization is a path to enable interoperability of network services between operators and address limitations that arise in the deployment of services, as explained in Section~\ref{sec:stand}. Another parallel track towards interoperability is a broad adoption of software components and broad agreements on APIs along data and information models fueled by re-usable open source artifacts. 

\subsection{Resource and Service Modeling}

Network services need to be efficiently modeled towards deploying resource requirements, configuration parameters, management policies, and performance metrics. Service modeling will enable abstraction of resources and capabilities of underlying layers. It simplifies the understanding of functions and provides a generic way to represent resource and service. 

However, it is a major challenge to translate higher-level policies, which are generated from the resource allocation and optimization mechanisms, into a lower level configuration. Templates and standards should be developed to guarantee automated and consistent translation~\cite{YongLi2015Software-DefinedSurvey}. Besides, the standardization can enable the interoperability and integration of network services templates and addresses limitations arising in the deployment of services in heterogeneous landscape.

There are templates and data modeling languages for \acrfull{nfv} and \acrfull{ns} such as TOSCA, YANG, and HOT. In addition, some organizations propose their approaches to the definition of Network Services, e.g., Open Baton and Gohan.

\gls{etsi} \gls{nfv} \gls{mano} proposes VNF and Network Service descriptors as templates for the definition of functions and services. According to \gls{etsi}, \gls{ns} is defined as a set of \glspl{vnf} and/or \glspl{pnf} interconnected by \glspl{vl} and one or more \acrlong{vnffg}. 

On the other hand, \gls{etsi} \gls{ns} specifies lowest level resources such as CPU, memory, and network, but it does not extend the resource modeling and does not define a data model to the descriptors~\cite{Mijumbi2016ManagementVirtualizationb}. Thus, its approach is driven to single domain environment~\cite{Garay2016ServiceForward}. 

On the other hand, the \gls{ietf} \gls{sfc} provides the ability to define an ordered list of network services, or service functions (e.g., firewalls, load balancers, DPI) connecting them in a virtual chain. However, \gls{sfc} does not describe the underlying resource, since its primary focus is service operation, apart from the forwarding topology. As opposed to ETSI, SFC scope covers multi-domain connections.   

Resource and service modeling in softwarized networks including multi-domain scenarios need further work. This evolution will enable interoperability of network services and the correct mapping between the high-level configuration and the underlying infrastructure. Currently, the interoperability among the diverse orchestration platforms does not exist.

\subsection{Network Service Lifecycle Management}

Network service lifecycle consists in all process for deployment, execution, and termination of a network service. The Network Service Lifecycle Management is fundamental to ensure the correct operation of the service.

Nevertheless, the network services can have specific lifecycle management requirements. For example, an NS can use specific resources as \gls{sriov}~\cite{5416637} and DPDK or need resources across various domains. This type of requirements becomes harder the service deployment.

One possible solution is service lifecycle automation. It enables lifecycle management without human intervention. Automation can be obtained through heuristic algorithms and machine learning techniques. ONAP is working on new closed control loops (e.g., CLAMP - Closed Loop Automation Management Platform)\footnote{https://github.com/onap/clamp} towards providing automation, performance optimization and Service Lifecycle Management, eventually leveraging network analytics and machine learning assisted decisions.
Nevertheless, many aspects of run-time (day 2) workflow modeling and implementation remain open, with TOSCA extensions and BPMN/BPML approaches~\cite{DBLP:conf/closer/CalcaterraCMT17} undergoing improvements to meet the needs of NSO-based lifecycle automation. 


\subsection{Performance and  Service Assurance}

The changes that orchestration technology brings to the telecommunication infrastructures make them increasingly virtualized and software-based. So, performance is a constant challenge in a highly dynamic environment of virtual functions and services.  

This change reflects on enabling technologies. For instance, the \gls{nfv} should meet performance requirements to support, in a standard server, the packet processing, including high I/O speed, fast transmission, and short delays~\cite{YongLi2015Software-DefinedSurvey}. The \glspl{vnf} must achieve a performance comparable to specialized hardware. According to~\cite{Mijumbi2016NetworkChallenges}, some applications require specific capabilities, but virtualization can degrade their performance. This generates a trade-off between performance and flexibility. However, recent advances in CPU and virtualization technologies are overcoming these challenges include \gls{dpdk}~\cite{LinuxFoundationDPDKKit} -- libraries and drivers for fast packet processing, NetVM~\cite{7036139} -- enabling high bandwidth network functions to operate at near line speed, and ClickOS~\cite{Martins:2014:CAN:2616448.2616491} -- minimalist operating that supports high throughput, low delay, and isolation. Likewise, the document~\cite{ETSIGSPractises} of the \gls{etsi}  provides a set of recommendations on the minimum requirements that the hardware and virtualized layer should have to achieve high performance.

Another question is performance monitoring coupled with Network Services maintenance. Both require a global view of the resources and a unified control and optimization process with various optimization policies running in it. The monitoring is required to avoid the violation of \glspl{sla} in the Service layer. In order to keep NS performance, it is demanded that the system equally performs in different layers. In multi-domain scenarios, this becomes more complex because it is necessary the exchange of information and resources between different organizations/domains~\cite{md2}. 
VNF benchmarking~\cite{7313620} and NS chain profiling~\cite{7956044} coupled to NSO lifecycles and run-time MANO resource allocation and management decisions are potential techniques towards service guarantees and SLA compliance.  

In addition, a better composition between the traffic forwarding and \gls{nf} placement is required towards optimizing the \gls{ns} deployment. The first steps to provide service performance guarantees are to avoid heavily loaded service nodes and to identify bottleneck links. Algorithms and machine learning techniques can archive better results in this composition.   

Thus, how to achieve high performance is an important problem in the research and development of \gls{nso} solutions. Projects within the 5G Infrastructure Public Private Partnership (5G-PPP)~\cite{elayoubi:hal-01488208} are targeting enhanced performance towards better user experience. 

\subsection{Scalability}

Some studies assume that 5G network might connect 50 billion devices until 2020~\cite{Panwar2016ACommunication},~\cite{Evans2011TheEverything}. This growth is due to the emergence of vertical industries such as Internet of Things, Smart Cities, and Sensor Networks. In this scenario, orchestration process requires the ability to handle the growth of networks and services to support the huge amount of connected nodes.

In addition, the network services can be deployed over different domains managed by third parties, infrastructure covering large geographical space and diverse type of resources such as access, transport, and core networks. This environment demands high scalability of the components involved, including orchestrators, controllers, and managers. 

Most current \gls{nso} use cases are just based on deploying a network service in a controlled scenario. Just a use case is not able to check the scalability of the solution. In a production environment, the orchestrator is responsible for orchestrating millions of customers and services at the same time. Hence, scalability is an important feature for \gls{nso} success.

Some orchestration solutions mainly focus on centralized solutions, which pose scalability issues. The works~\cite{Alvizu2016AdvanceEra} and~\cite{Garay2016ServiceForward} suggest different orchestrators involved in the orchestration process of end-to-end network services, not being limited to a single orchestrator. However, there are several particularities on each layer that could be better explored with specific orchestrators, instead of adopting a global orchestrator approach. In this way, we argue that the whole orchestration process can experience better results if split among different actors (or orchestrators). 

A key challenge is therefore to develop an orchestration process that is massively scalable. This process could involve one or more orchestrators, becoming open and flexible enough to address future applications and enable the integration with external components. The orchestration must avoid the congestions and bottlenecks in the management and orchestration plane to handle the requests for network services.
 
\subsection{Security and Resiliency}

Softwarized networks modify the way how services are deployed replacing the hardware-based network service components with software-based solutions~\cite{Draxler2017SONATA:Networksb}. Through technologies such as \gls{sdn} and \gls{nfv}, such network can provide automation, programmability, and flexibility. Generally, it depends on centralized control, which leads to risks to security and resiliency~\cite{Arfaoui2017SecurityDirections}. Thus, new protection capabilities need to be put in place, including advanced management capabilities such as authentication, access control, and fault management. 

Security and resiliency must be considered both in design and operation stages of network services. Typically, the services are deployed first, prior to any efforts regarding security development. However, security must be a mandatory issue, mainly in a highly connected and virtualized environment. 

Service instantiation involves automated processes that add and delete network elements and functions without human intervention. A critical problem is the addition of a malicious node that can perform attacks, catch valuable information and even the disruption of the entire services.      

An essential requirement for a multi-domain orchestration platform is the capability to hide specific details of each domain. This ensures privacy and confidentiality of the domains, preserving capabilities and resources to an external component~\cite{francescon2017x}.

Resilience in main NSO components such as orchestrators, controllers, and managers is also a critical problem because it can impact directly in overall service operation. Besides, open interfaces that support network programmability and \gls{nso} components communication with other external elements such as \gls{oss} and other orchestrators are an open issue and a hot topic in research ~\cite{Ordonez-Lucena2017NetworkChallenges}, ~\cite{Arfaoui2017SecurityDirections},~\cite{7345422}. In the same direction, the 5G-PPP published a white paper~\cite{elayoubi:hal-01488208} suggesting that the orchestration platform must be secure, reliable and flexible.